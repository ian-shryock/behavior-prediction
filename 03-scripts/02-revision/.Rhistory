max = max(x, na.rm = T),
min = min(x, na.rm = T))
}
shp <- shp_recode %>%
filter(category != "correlates") %>%
unnest(data) %>%
select(name, year, SID, value) %>%
filter(complete.cases(.)) %>%
group_by(name, year, SID) %>%
summarize(value = mean(value)) %>%
ungroup() %>%
pivot_wider(names_from = "name", values_from = "value") %>%
group_by(SID) %>%
filter(n() >= 5) %>%
ungroup()
shp_years <- shp %>%
group_by(SID) %>%
filter(year == median(year)) %>%
ungroup() %>%
select(m_year = year, SID)
shp_corr <- shp_recode %>%
filter(category == "correlates") %>%
select(-category) %>%
unnest(data) %>%
mutate(year = ifelse(name == "parEdu", 0, year)) %>%
group_by(name) %>% nest() %>% ungroup() %>%
mutate(data = map(data, ~(.) %>%
filter(!is.na(value)) %>%
mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
group_by(comp_rule, SID, year, long_rule) %>%
nest() %>%
ungroup() %>%
mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
unnest(data) %>%
right_join(shp_years) %>%
filter(year <= m_year)
# summarize(value = fun_call(value, comp_rule)) %>%
# ungroup() %>%
# mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
))
comp_fun <- function(d, rule, p_year){
print(paste(rule, p_year))
d %>%
group_by(SID, name) %>%
summarize(value = fun_call(data, rule)) %>%
ungroup() %>%
distinct()
}
# composite ACROSS years
shp_corr <- shp_corr %>%
unnest(data) %>%
mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
filter(year <= m_year) %>%
group_by(m_year, long_rule) %>%
nest() %>%
ungroup() %>%
mutate(data = pmap(list(data, long_rule, m_year), comp_fun)) %>%
unnest(data) %>%
mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
select(-long_rule) %>%
spread(name, value) %>%
filter(!is.na(SID))%>%
mutate(yearBrth = ifelse(yearBrth < 1000, yearBrth + 1000, yearBrth)
, age = m_year - yearBrth)
shp_corr
save(shp, shp_corr, file = sprintf("%s/01_data/01_clean/01_shp-clean.RData", wd))
rm(list = ls()[grepl("shp", ls())])
# list of all codebook sheets
sheets <- sprintf("%s/02_codebooks/01_master-codebook-2021-03-17.xlsx", wd) %>% excel_sheets()
# function for reading in sheets
read_fun <- function(x){
sprintf("%s/02_codebooks/01_master-codebook-2021-03-17.xlsx", wd) %>% read_xlsx(., sheet = x)
}
# read in sheets and index source
codebook <- tibble(
study = sheets,
codebook = map(study, read_fun)
)
liss_read_fun <- function(x){
sprintf("%s/liss/%s", data_path, x) %>% haven::read_sav(.) %>% select(one_of(old.names))
}
liss_codebook <- (codebook %>% filter(study == "liss"))$codebook[[1]]
old.names <- unique(liss_codebook$orig_itemname) %>% str_to_lower
datasets <- sprintf("%s/liss", data_path) %>% list.files()
liss <- tibble(datasets = datasets) %>%
mutate(data = map(datasets, liss_read_fun))
liss <- reduce(liss$data, full_join) %>% haven::zap_labels(.)
save(liss, file = sprintf("%s/01_data/01_clean/04_liss-raw.RData", wd))
avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.))) %>%
separate(ds, c("ds", "year", "scrap1", "scrap2"), sep = "_") %>%
separate(year, c("year", "month"), -2) %>%
select(year, month, data) %>%
unnest(data) %>%
group_by(nomem_encr) %>%
summarise(gebjaar = Mode(gebjaar)
, geslacht = Mode(geslacht)) %>%
ungroup()
avars
avars
old.names
avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.)))
avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.))) %>%
separate(ds, c("ds", "year", "scrap1", "scrap2"), sep = "_") %>%
separate(year, c("year", "month"), -2) %>%
select(year, month, data) %>%
unnest(data)
avars
liss_long
tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.)))
avars
avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.))) %>%
separate(ds, c("ds", "year", "scrap1", "scrap2"), sep = "_") %>%
separate(year, c("year", "month"), -2) %>%
select(year, month, data) %>%
unnest(data) %>%
pivot_longer(cols = c(burgstat, geslacht, belbezig, gebjaar)
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T)
avars
liss_long
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
full_join(avars)
liss_recode
liss_long
liss_codebook %>%
filter(category %in% c("overall", "domain")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup()
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, ~(.) %>% left_join(liss_long %>% rename(SID = nomem_encr))))
avars
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
full_join(avars) %>%
mutate(year = as.numeric(year))
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, ~(.) %>% left_join(liss_long %>% rename(SID = nomem_encr))))
liss_recode
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, ~(.) %>% left_join(liss_long %>% rename(SID = nomem_encr))))
liss_recode
liss_recode
liss
liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates"))
rename_fun <- function(df){
df %>% left_join(liss_long %>% rename(SID = nomem_encr))
}
debug(rename_fun)
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, rename_fun))
df
df %>% left_join(liss_long %>% rename(SID = nomem_encr))
liss_long %>% filter(orig_itemname == "ch07a089")
df %>% left_join(liss_long %>% rename(SID = nomem_encr))
df %>% right_join(liss_long %>% rename(SID = nomem_encr))
df
liss_long
Q
liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, year))
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, year)) %>%
full_join(avars) %>%
mutate(year = as.numeric(year))
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, as.numeric(year))) %>%
full_join(avars) %>%
mutate(year = as.numeric(year))
liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, year))
avars
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, year)) %>%
full_join(avars %>% mutate(year = as.numeric(year)))
liss_long
rename_fun <- function(df){
df %>% left_join(liss_long %>% rename(SID = nomem_encr))
}
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, rename_fun))
liss_long
avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% haven::read_sav(.) %>% select(one_of(old.names)) %>% haven::zap_labels(.))) %>%
separate(ds, c("ds", "year", "scrap1", "scrap2"), sep = "_") %>%
separate(year, c("year", "month"), -2) %>%
select(year, month, data) %>%
unnest(data) %>%
pivot_longer(cols = c(burgstat, geslacht, belbezig, gebjaar)
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
group_by(orig_itemname, nomem_encr, year) %>%
summarize(value = Mode(value)) %>%
ungroup()
avars
liss_long <- liss %>%
pivot_longer(cols = -nomem_encr
, names_to = "orig_itemname"
, values_to = "value"
, values_drop_na = T) %>%
left_join(liss_codebook %>% select(orig_itemname, year)) %>%
full_join(avars %>% mutate(year = as.numeric(year)))
liss_long
debug(rename_fun)
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, rename_fun))
df
Q
# list of all codebook sheets
sheets <- sprintf("%s/02_codebooks/01_master-codebook-2021-03-17.xlsx", wd) %>% excel_sheets()
# function for reading in sheets
read_fun <- function(x){
sprintf("%s/02_codebooks/01_master-codebook-2021-03-17.xlsx", wd) %>% read_xlsx(., sheet = x)
}
# read in sheets and index source
codebook <- tibble(
study = sheets,
codebook = map(study, read_fun)
)
liss_codebook <- (codebook %>% filter(study == "liss"))$codebook[[1]]
old.names <- unique(liss_codebook$orig_itemname) %>% str_to_lower
rename_fun <- function(df){
df %>% left_join(liss_long %>% rename(SID = nomem_encr))
}
# join data with recoding info
liss_recode <- liss_codebook %>%
filter(category %in% c("overall", "domain", "correlates")) %>%
select(category, name, itemname, wave, year, orig_itemname, reverse_code:recode, mini, maxi, comp_rule, long_rule) %>%
distinct() %>%
group_by(category, name, mini, maxi) %>%
nest() %>%
ungroup() %>%
mutate(data = map(data, rename_fun))
liss_recode
# recode
recode_fun <- function(rule, y, year){
x <- y$value
if(!is.na(rule)){y$value <- eval(parse(text = rule))}
return(y)
}
liss_recode <- liss_recode %>%
mutate(data = map(data, ~(.) %>%
group_by(recode, year) %>%
nest() %>%
ungroup() %>%
mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
unnest(data) %>%
mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))
liss_recode
liss_recode
rev_code_fun <- function(df, mini, maxi){
df %>%
mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value,
reverse.code(-1, value, mini = mini, maxi = maxi)))
}
rev_code_fun <- function(df, mini, maxi){
df %>%
mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value,
reverse.code(-1, value, mini = mini, maxi = maxi)))
}
# reverse code
liss_recode <- liss_recode %>%
mutate(data = map(data, rev_code_fun))
# reverse code
liss_recode <- liss_recode %>%
mutate(data = pmap(list(data, mini, maxi), rev_code_fun))
liss_recode
pomp_fun <- function(d, mini, maxi){
d %>%
mutate(value = ((value - mini)/(maxi-mini))*10) # pomp)
}
liss2 <- liss_recode %>%
filter(category != "correlates") %>%
mutate(data = pmap(list(data, mini, maxi), pomp_fun)) %>%
unnest(data) %>%
select(name, year, SID, value) %>%
filter(complete.cases(.)) %>%
group_by(name, year, SID) %>%
summarize(value = mean(value)) %>%
ungroup() %>%
pivot_wider(names_from = "name", values_from = "value") %>%
group_by(SID) %>%
filter(n() >= 5) %>%
ungroup()
liss_years <- liss2 %>%
group_by(SID) %>%
filter(year == median(year)) %>%
ungroup() %>%
select(m_year = year, SID)
liss_years
liss_corr <- liss_recode %>%
filter(category == "correlates") %>%
select(-category) %>%
unnest(data) %>%
mutate(year = ifelse(name == "parEdu", 0, year)) %>%
group_by(name) %>% nest() %>% ungroup() %>%
mutate(data = map(data, ~(.) %>%
filter(!is.na(value)) %>%
mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
group_by(comp_rule, SID, year, long_rule) %>%
nest() %>%
ungroup() %>%
mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
unnest(data) %>%
right_join(liss_years) %>%
filter(year <= m_year)
# summarize(value = fun_call(value, comp_rule)) %>%
# ungroup() %>%
# mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
))
comp_fun <- function(d, rule, p_year){
print(paste(rule, p_year))
d %>%
group_by(SID, name) %>%
summarize(value = fun_call(data, rule)) %>%
ungroup() %>%
distinct()
}
# composite ACROSS years
liss_corr <- liss_corr %>%
unnest(data) %>%
mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
filter(year <= m_year) %>%
group_by(m_year, long_rule) %>%
nest() %>%
ungroup() %>%
mutate(data = pmap(list(data, long_rule, m_year), comp_fun)) %>%
unnest(data) %>%
mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
select(-long_rule) %>%
spread(name, value) %>%
filter(!is.na(SID))%>%
mutate(yearBrth = ifelse(yearBrth < 1000, yearBrth + 1000, yearBrth)
, age = m_year - yearBrth)
liss_corr
save(liss, file = sprintf("%s/01_data/01_clean/04_liss-raw.RData", wd))
liss <- liss_recode %>%
filter(category != "correlates") %>%
mutate(data = pmap(list(data, mini, maxi), pomp_fun)) %>%
unnest(data) %>%
select(name, year, SID, value) %>%
filter(complete.cases(.)) %>%
group_by(name, year, SID) %>%
summarize(value = mean(value)) %>%
ungroup() %>%
pivot_wider(names_from = "name", values_from = "value") %>%
group_by(SID) %>%
filter(n() >= 5) %>%
ungroup()
save(liss, liss_corr, file = sprintf("%s/01_data/01_clean/01_liss-clean.RData", wd))
rm(list = ls()[grepl("liss", ls())])
setwd(sprintf("%s/03-scripts/01-book", local_path))
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, error = F)
options(knitr.kable.NA = '')
library(knitr)              # creating tables
library(kableExtra)         # formatting and exporting tables
library(rio)                # importing html
library(readxl)             # read excel codebooks and documentation
library(psych)              # biscuit / biscwit
library(glmnet)             # elastic net regression
library(glmnetUtils)        # extension of basic elastic net with CV
library(caret)              # train and test for random forest
library(vip)                # variable importance
library(Amelia)             # multiple imputation (of time series)
library(lubridate)          # date wrangling
library(gtable)             # ggplot friendly tables
library(grid)               # ggplot friendly table rendering
library(gridExtra)          # more helpful ggplot friendly table updates
library(plyr)               # data wranging
library(tidyverse)          # data wrangling
library(ggdist)             # distributional plots
library(ggridges)           # more distributional plots
library(cowplot)            # flexibly arrange multiple ggplot objects
library(tidymodels)         # tidy model workflow and selection
# library(modeltime)          # tidy models for time series
library(furrr)              # mapping many models in parallel
res_path <- "https://github.com/emoriebeck/behavior-prediction/raw/main"
local_path <- "~/Box/network/other projects/idio prediction"
# list of all codebook sheets
ipcs_codebook <- import(file = sprintf("%s/01-codebooks/codebook.xlsx", res_path), which = 2) %>%
as_tibble()
ipcs_codebook
outcomes <- ipcs_codebook %>% filter(category == "outcome") %>% select(trait, long_name)
ftrs <- import(file = sprintf("%s/01-codebooks/codebook.xlsx", res_path), which = 3) %>%
as_tibble()
ipcs_codebook %>% filter(category == "BFI-2")
ipcs_codebook %>% filter(category == "Affect")
ipcs_codebook %>% filter(category == "sit")
ipcs_codebook %>% filter(category == "S8-I")
load(url(sprintf("%s/04-data/01-raw-data/cleaned_combined_2020-05-06.RData", res_path)))
dem <- baseline %>%
select(SID:race) %>%
mutate(age = year(ymd_hms(StartDate)) - as.numeric(YOB),
StartDate = as.Date(ymd_hms(StartDate)),
race = factor(race, 0:3, c("White", "Black", "Asian", "Other"))) %>%
select(-YOB)
dem %>%
summarize(n = length(unique(SID)),
gender = sprintf("%i (%.2f%%)",sum(gender == "Female"), sum(gender == "Female")/n()*100),
age = sprintf("%.2f (%.2f)", mean(age, na.rm = T), sd(age, na.rm = T)),
white = sprintf("%i (%.2f%%)"
, sum(race == "White", na.rm = T)
, sum(race == "White", na.rm = T)/n()*100),
black = sprintf("%i (%.2f%%)"
, sum(race == "Black", na.rm = T)
, sum(race == "Black", na.rm = T)/n()*100),
asian = sprintf("%i (%.2f%%)"
, sum(race == "Asian", na.rm = T)
, sum(race == "Asian", na.rm = T)/n()*100),
other = sprintf("%i (%.2f%%)"
, sum(race == "Other", na.rm = T)
, sum(race == "Other", na.rm = T)/n()*100),
StartDate = sprintf("%s (%s - %s)", median(StartDate),
min(StartDate), max(StartDate)))
dem %>%
kable(., "html"
, col.names = c("ID", "Start Date", "Gender", "Race/Ethnicity", "Age")
, align = rep("c", 5)
, caption = "<strong>Table S1</strong><br><em>Descriptive Statistics of Participants at Baseline<em>") %>%
kable_styling(full_width = F) %>%
scroll_box(height = "900px")
# automatically create a bib database for R packages
knitr::write_bib(c(
.packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
# list of all codebook sheets
ipcs_codebook <- import(file = sprintf("%s/01-codebooks/codebook.xlsx", res_path), which = 2) %>%
as_tibble()
ipcs_codebook
# list of all codebook sheets
ipcs_codebook <- import(file = sprintf("%s/01-codebooks/codebook.xlsx", res_path), which = 2) %>%
as_tibble()
ipcs_codebook
setwd(sprintf("%s/03-scripts/01-book", local_path))
bookdown::render_book("index.Rmd")
participants <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1r808gQ-LWfG98J9rvt_CRMHtmCFgtdcfThl0XA0HHbM/edit#gid=16299281", sheet = "ESM") %>%
select(SID, Name, Email) %>%
mutate(new = seq(1, nrow(.), 1),
new = ifelse(new < 10, paste("0", new, sep = ""), new))
??rolling_origin
